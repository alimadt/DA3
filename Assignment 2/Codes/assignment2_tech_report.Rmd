---
title: "Assignment 2: Technical Report"
author: "Alima Dzhanybaeva"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r message=FALSE, warning=FALSE, include=FALSE}
# Necessary libraries
library(tidyverse)
library(data.table)
library(ggplot2)
library(modelsummary)
library(directlabels)
library(caret)
library(rattle)
library(cowplot)
library(ranger)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Downloading cleaned data
df <- read_csv('cleaned.csv')
```

 
```{r message=FALSE, warning=FALSE, include=FALSE}
# Looking for interactions
price_diff_by_variables2 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){

  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(
      Mean = mean(price, na.rm=TRUE),se = sd(price)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(
    stats, 
    aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(
      stat='identity', 
      position = position_dodge(width=0.9), 
      alpha=0.8)+
    geom_errorbar(
      aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
      position=position_dodge(width = 0.9), 
      width = 0.25)+
    scale_color_manual(
      name=dummy_lab,
      values=c('darkblue','red')) +
    scale_fill_manual(
      name=dummy_lab,
      values=c('darkblue','red')) +
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme_bw()+
    theme(
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      panel.border=element_blank(),
      axis.line=element_line(),
      legend.position = "top",
      legend.box = "vertical",
      legend.text = element_text(size = 5),
      legend.title = element_text(size = 5, face = "bold"),
      legend.key.size = unit(x = 0.4, units = "cm")
    )
}

p1 <- price_diff_by_variables2(df, "f_property_type", "d_air_conditioner", "Property Type", "Air Conditioner")
p2 <- price_diff_by_variables2(df, "f_property_type", "d_pool", "Property Type", "Pool")
p3 <- price_diff_by_variables2(df, "f_property_type", "d_hot_tub", "Property Type", "Hot Tub")
p4 <- price_diff_by_variables2(df, "f_property_type", "d_sound_system", "Property Type", "Sound System")
p5 <- price_diff_by_variables2(df, "f_property_type", "d_coffee_machine", "Property Type", "Coffee Machine")
p6 <- price_diff_by_variables2(df, "f_property_type", "d_dishwasher", "Property Type", "Dishwasher")
p7 <- price_diff_by_variables2(df, "f_property_type", "d_wifi", "Property Type", "Wifi")
p8 <- price_diff_by_variables2(df, "f_property_type", "d_TV", "Property Type", "TV")
p9 <- price_diff_by_variables2(df, "f_property_type", "d_balcony", "Property Type", "Balcony")
p10 <- price_diff_by_variables2(df, "f_property_type", "d_gym", "Property Type", "Gym")
p11 <- price_diff_by_variables2(df, "f_property_type", "d_hair_dryer", "Property Type", "Hair Dryer")
p12 <- price_diff_by_variables2(df, "f_property_type", "d_stove", "Property Type", "Stove")
p13 <- price_diff_by_variables2(df, "f_property_type", "d_breakfast", "Property Type", "Breakfast")
p14 <- price_diff_by_variables2(df, "f_property_type", "d_good_view", "Property Type", "Good View")
g_interactions1 <- plot_grid(p1, p2, p3, p4, p6, p8, p9, p10, p14, nrow=4, ncol=2) 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Defining variables
basic_lev <- c("accommodates", "f_property_type", "beds", "n_days_since")

# Factorized variables
basic_add <- c("f_bathroom", "f_neighbourhood_group_cleansed")

# reviews
reviews <- c("f_number_of_reviews", "review_scores_rating", 
             "reviews_per_month")
# higher orders
poly_lev <- c("accommodates2", "n_days_since2", "n_days_since3")

# Dummy Variables 
dummies <- grep("^d_.*", names(df), value = TRUE)

# Interaction terms
X1 <- c("f_property_type * accommodates", "f_property_type * f_neighbourhood_group_cleansed")

# Additional dummies based on graphs suggestion
X2  <- c("f_property_type*d_air_conditioner", 
         "f_property_type*d_pool",
         "f_property_type*d_hot_tub",
         "f_property_type*d_dishwasher",
         "f_property_type*d_TV",
         "f_property_type*d_balcony", 
         "f_property_type*d_gym",
         "f_property_type*d_good_view")

# all dummies with property type
X3  <- c("accommodates*f_neighbourhood_group_cleansed",
         paste0("(f_property_type) * (",
                paste(dummies, collapse=" + "),")"))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create models in levels models: 1-8
modellev1 <- " ~ accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews, poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies, X3),collapse = " + "))

model_table_view <- data.frame(Model = c('M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8'),
                               Predictors = c('# of Accommodates', 
                               'M1 + Property Type + Number of Beds + Number of Days Since the First Review', 
                               'M2 + # of bathrooms + Neighbourhood group + Reviews per Month + Review Score Rating + # of Reviews',
                               'M3 + # of Accommodates Squared + Squared and Cubic Terms # of Days Since the First Review',
                               'M4 + (Property Type * Number of Accommodates) + (Property Type * Neighbourhood Group)',
                               'M5 + (Property Type * several Amenities Dummies)',
                               'M6 + all Dummy Vars',
                               'M7 + (# of Accommodates * Neighbourhood group) + (Property Type * all Dummy Vars)'))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create a holdout set
smp_size <- floor(0.2 * nrow(df))
set.seed(12345)
holdout_ids <- sample(seq_len(nrow(df)), size = smp_size)
df$holdout <- 0
df$holdout[holdout_ids] <- 1
#Hold-out set
data_holdout <- df %>% filter(holdout == 1)
#Working set
data_work <- df %>% filter(holdout == 0)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Working data set:
k_folds=5 # number of folds
set.seed(12345)
folds_i <- sample(rep(1:k_folds, length.out = nrow(data_work) ))
mse_lev <- function(pred, y) {
  (mean((pred - y)^2, na.rm=T))
}
# Create Results
model_results_cv <- list()
for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  # Initialize values
  rmse_train <- c()
  rmse_test <- c()
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  # Do the k-fold estimation
  for (k in 1:k_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)
    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train[,yvar] %>% pull)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_test[,yvar] %>% pull)**(1/2)
  }
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}

model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)
t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                  "Test RMSE")
OLS_models <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(OLS_models) <- column_names

# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))

model_result_plot <- ggplot(data = t1_levels,
                                   aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
  geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
  scale_color_manual(name="",
                     values=c("#fde725","#440154")) +
  geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  theme_bw()
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Set lasso tuning parameters:
train_control <- trainControl(method = "cv", number = k_folds)
tune_grid <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))

vars_model_1 <- c(basic_lev, basic_add, reviews, dummies)
vars_model_7 <- c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies) # Model 7
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# OLS 
set.seed(12345)
system.time({
  ols_model <- train(
    formula(paste0("price ~", paste0(vars_model_7, collapse = " + "))),
    data = data_work,
    method = "lm",
    trControl = train_control
  )
})
ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# LASSO               
set.seed(12345)
system.time({
  lasso_model <- caret::train(
    formula(paste0("price ~", paste0(vars_model_7, collapse = " + "))),
    data = data_work,
    method = "glmnet",
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    preProcess = c("center", "scale"),
    trControl = train_control
  )
})

lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  rename(coefficient = `s1`)
print(lasso_coeffs)
lasso_coeffs_nz <- lasso_coeffs %>%
  filter(coefficient!=0)

lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])
regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_nz, by = "variable", all=TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# CART        
set.seed(12345)
system.time({
  cart_model <- train(
    formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
    data = data_work,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Random Forest     
tune_grid <- expand.grid(
  .mtry = c(8),
  .splitrule = "variance",
  .min.node.size = c(50)
)

set.seed(12345)
system.time({
rf_model <- train(
  formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
  data = data_work,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# GBM              
gbm_grid <-  expand.grid(interaction.depth = c(5, 10),
                         n.trees = 250, 
                         shrinkage = 0.1,
                         n.minobsinnode = 20
)

set.seed(12345)

system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
                     data = data_work,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model$finalModel$mtry,
  rf_model$finalModel$min.node.size
),
nrow=1, ncol=2,
dimnames = list("Model A",
                c("Min vars","Min nodes"))
)

final_models <-
  list("OLS" = ols_model,
       "LASSO" = lasso_model,
       "CART" = cart_model,
       "Random forest"= rf_model,
       "GBM"  = gbm_model
       )
results <- resamples(final_models) %>% summary()

results_r2 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV R-squared" = ".")

results_rmse <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

result_holdout_rmse <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Diagnostics

# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}
rf_model_var_imp <- ranger::importance(rf_model$finalModel)/1000
rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

# Importance plot for top 10
rf_model_var_imp_plot_b <- ggplot(
  rf_model_var_imp_df[1:10,], 
  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  labs(title = 'Simple variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4)) +
  theme_bw()

# Grouped importance plot
varnames <- rf_model$finalModel$xNames

f_neighbourhood_group_cleansed_varnames <- grep("f_neighbourhood_group_cleansed",varnames, value = TRUE)

f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_group_cleansed=f_neighbourhood_group_cleansed_varnames,
               f_property_type = f_property_type_varnames,
               f_bathroom = "f_bathroom",
               n_days_since = "n_days_since",
               accommodates = "accommodates",
               beds = "beds")

rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)

rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                            imp = rf_model_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_var_imp_grouped_plot <- ggplot(
  rf_model_var_imp_grouped_df, 
  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +   
  xlab("Variable Name") +
  labs(title = 'Grouped variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4)) +
  theme_bw()
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# PDP: partial dependence plots 

# 1) Number of accommodates
pdp_n_acc <- pdp::partial(rf_model, 
                          pred.var = "accommodates", 
                          pred.grid = distinct_(data_holdout, "accommodates"), 
                          train = data_work)

pdp_acc_plot<- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color='black', size=2) +
  geom_line(color='black', size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  labs(title = 'Partial dependence plot for # of accommodates') + 
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bw()

# 2) Property type
pdp_propertytype <- pdp::partial(rf_model, pred.var = "f_property_type", pred.grid = distinct_(data_holdout, "f_property_type"), train = data_work)

pdp_ptype_plot <- pdp_propertytype %>%
  autoplot( ) +
  geom_point(color='black', size=2) +
  geom_line(color='black', size=1) +
  ylab("Predicted price") +
  xlab("Property type") +
  labs(title = 'Partial dependence plot for Property Type') + 
  theme_bw() 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Subsample performance: RMSE / mean(y)
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model, newdata = data_holdout))

first <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(accommodates <= 3, "small apt", "bigger apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )
second <- data_holdout_w_prediction %>%
  group_by(f_neighbourhood_group_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )
third <- data_holdout_w_prediction %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )
fourth <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )
# Save output
colnames(first) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(second) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(third) <- c("", "RMSE", "Mean price", "RMSE/price")
fourth <- cbind("All", fourth)
colnames(fourth) <- c("", "RMSE", "Mean price", "RMSE/price")
line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Neighbourhood", "", "", "")
result_2 <- rbind(line2, first, line1, third, line3, second, fourth) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
Ylev <- data_holdout[["price"]]
# Predicted values
prediction_holdout_pred <- as.data.frame(predict(gbm_model, newdata = data_holdout, interval="predict")) 
predictionlev_holdout <- cbind(data_holdout[,c("price","accommodates")],
                               prediction_holdout_pred)
# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout[,3] )
# Check the differences
d$elev <- d$ylev - d$predlev
# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = "darkblue", size = 1,
                 alpha = 0.5, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 350, yend =350), size=0.8, color="black", linetype=2) +
  labs(y = "Price", x = "Predicted price") +
  theme_bw() 
level_vs_pred
```

## $\text{\underline{Introduction}}$

In this project, I tried to find the best price prediction model for mid-size apartments in Los Angeles. The results for 5 models (OLS, LASSO, CART, Random Forest, GBM) showed the lowest RMSE of 73.69 for *Random Forest*,  suggesting the best predictive performance.

## $\text{\underline{Cleaning data}}$

The original dataset for Los Angeles includes 40438 observations and 75 variables, and was scraped from Airbnb on December 7th 2022.

**Dropping variables:**

- Firstly, the variables that won't be helpful for the prediction of prices (i.e. 'listing.url', 'scrape_id', 'description', 'picture_url'  etc.) were dropped.

- After the check for missing values the following variables that are assumed to be not that significant and included a lot of NAs were also dropped:
'host_neighbourhood', 'neighbourhood' ('neighbourhood_cleansed' will be used instead), 'bathrooms' ('bathroom_text' will be transformed and used instead), 'bedrooms', 'last_review', 'host_response_time', 'host_response_rate', 'host_acceptance_rate'.

**Filtering:**

- *Price*: The 'price' variable was filtered for values that are more than 0 (as it does not make sense when the place is rented fo free) and less than 800 (800 is 95% percentile).

- *Property type*: The goal of the project is to predict prices for apartments, therefore, the dataset was filtered for following property types: "Entire condo","Entire loft", "Entire serviced apartment", "Entire home/apt", "Entire rental unit".

- *Number of accommodates*: As the mid-sized apartments are the focus of this assignment, the 'accommodates variable' was filtered for values between 2 and 6.

**Transformation of the variables**:

- Values for the variables 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable' were changed from TRUE|FALSE to 1|0.

- All the text from 'bathrooms_text' was deleted so the variable can be converted to numerical, and the name was changed to 'bathrooms'.

- Factoring variables 'property_type', 'neighborhood_group_cleansed', 'neighborhood_cleansed'.

**Creation of new variables on the basis of existing ones:**

- *Amenities*: (1) the original variable was transformed into the list, (2) the unique values were observed, (3) dummy variables were created for the features that were the most frequent and are assumed to be significant for prices (TV, WiFi, hot tub, gym, sound system, dishwasher, pool, balcony, fridge, stove, coffee machine, good view, hair dryer, air conditioner, breakfast, wardrobe). The creation of the dummy variable on the example of 'TV' is presented in the code below:

```{r eval=FALSE}
df$d_fridge <- sapply(df$amenities, 
                      function(x) ifelse(length(grep("fridge", x, ignore.case = TRUE)) > 0 |
                                                         length(grep("refrigerator", x, ignore.case = TRUE)) > 0, 1, 0))
```

- *New factor variables*: (1) 'f_bathroom' with 3 categories: 0-1, 1-2, 2-5; (2) f_number_of_reviews with 3 categories: 0-1, 1-51, 51-maximum number of reviews; (3) f_minimum_nights with 3 categories: 1-2, 2-3, 3-maximum value for 'minimum nights'.

- *Functional forms*: (1) 'accommodates2' (number of accommodates squared); (2) 'ln_accommodates' (log of the number of accommodates); (3) 'ln_accommodates2' (log of the number of accommodates squared); (4) ln_beds (log of the number of beds); (3) ln_number_of_reviews (log of the number of reviews).

- *Number of days since the first review and its functional forms*: (1) creating 'days_since' variable by subtracting 'first_review' from 'calendar_last_scraped'; (2) functional forms of 'days_since': 'ln_days_since', 'ln_days_since2', 'ln_days_since3', 'n_days_since2', 'n_days_since3'. 

**Imputation of values:**

- For missing values in 'review_scores_rating', 'reviews_per_month', 'n_days_since' '0' was imputed, as NAs in these variables were found for observations that had 0 reviews. 
- For missing values in 'bathrooms' median value was imputed.
- For missing values in 'beds' it  was assumed that the number of beds is equal to number of accommodates.

After cleaning the data we are left with 11890 observations and 59 variables.

## $\text{\underline{Feature engineering}}$

The following groups of variables were defined:

- *Basic variables*: number of accommodates, property type, number of beds, number of days since the first review.

- *Factor variables*: factor variables for the number of bathrooms, neighbourhood group.

- *Reviews*: factor variable for number of reviews, rating, number of reviews per month.

- *Polynomials*: squared term of number of accommodates, sqaured and cubic terms of the days since the first review.

- *Dummy variables*: dummy variables for amenities, and such as

- *Interaction terms*: (X1) (property type * number of accommodates), (property type * neighbourhood group); (X2) on the basis of the graphs (Appendix: Graph1) it was decided to include the following interaction terms: (property type * (air conditioner, pool, hot tub, dishwasher, TV, Balcony, gym. good view); (X3) (number of accommodates * neighbourhood group), (property type * all dummy variables).

In the table below you can get familiar with 8 models and the variables that were added to each of them:

```{r echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(model_table_view) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

## $\text{\underline{Models evaluation}}$

The dataset was randomly divided to working set (80% of observations) and hold-out set (20% of observations):

```{r message=FALSE, warning=FALSE, eval=FALSE}
# Create a holdout set

smp_size <- floor(0.2 * nrow(df))
set.seed(12345)
holdout_ids <- sample(seq_len(nrow(df)), size = smp_size)
df$holdout <- 0
df$holdout[holdout_ids] <- 1

#Hold-out set
data_holdout <- df %>% filter(holdout == 1)

#Working set
data_work <- df %>% filter(holdout == 0)
```

Additionally, in order to estimate how well models are performing on a new, unseen data 5-fold cross-validation was implied.

The results of 8 OLS models are presented in the table below:

```{r echo=FALSE}
knitr::kable(OLS_models) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center")
```

Even though **Training RMSE** is the lowest for the *Model 8*, the difference between *Model 7* is negligible. Moreover, **BIC** and **Test RMSE** are the lowest for *Model 7*.

Therefore, *Model 7* model will be used for price prediction with **OLS** and **LASSO**.

And for **CART**, **Random Forest**, and **GBM** basic variables, factor variables, reviews, polynomials, and all dummy variables were used.

**Results**

According to the results presented in the table below, **Random Forest** showed the best performance with the lowest values for **CV RMSE**, **Holdout RMSE** and the highest value for **CV R-squared**.

```{r echo=FALSE, message=FALSE, warning=FALSE}
final_results_all_models <- cbind(results_rmse, result_holdout_rmse, results_r2)
knitr::kable(final_results_all_models) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center")
```

## $\text{\underline{Diagnostics}}$

As **Random Forest** is a "black box" method it is quite hard to understand the inner workings of the model and the relationship between the input variables and the predictions, as it is represented by a combination of many decision trees and not by mathematical formula like in linear regressions.

Nevertheless, we can try to uncover the obtained patterns with the variable importance plot, partial dependence plot, comparison of the measures for different subsamples, and plot for actual vs predicted prices

**Importance of the variables**

It is noticeable that 'f_bathroom' and 'accommodates' are the two most important variables, as they together account for around 30% in the 'Single variable importance plot' and 60% in the 'Grouped variable importance plot'.

Another important variables are: 'n_days_since', 'f_property_type', 'beds', 'f_neighbourhood_group_cleansed', and 'reviews_per_month'.

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='80%', fig.height=4,fig.align='center'}
rf_model_var_imp_plot_b
```

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='80%', fig.height=4,fig.align='center'}
rf_model_var_imp_grouped_plot
```

**Partial dependence plot**

As we can see from the partial dependence plot for the number of accommodates, as the number of guests that can check in into apartment rises the predicted price also increases. 

As for the partial dependence plot for property type, the lowest predicted price is observed for 'Entire Unit', while the highest is for 'Condominium'.

```{r echo=FALSE, fig.align='center', fig.height=4, message=FALSE, warning=FALSE, out.width='80%'}
pdp_acc_plot
```

```{r echo=FALSE, fig.align='center', fig.height=4, message=FALSE, warning=FALSE, out.width='80%'}
pdp_ptype_plot
```

**Performance across different sub samples**

From the table below we can observe, that **Random Forest ** does a better job with predicting prices for 'small apt', "Entire Unit', and 'City of Los Angeles', while the measures are worse for 'bigger apt', 'Condominium', and 'Other Cities'.

```{r echo=FALSE}
options(knitr.kable.NA = '')
knitr::kable(result_2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center")
```
\newpage

**Actual VS Predicted prices**

The figure below implies that the model is performing better for cheaper apartments.

```{r echo=FALSE, fig.align='center', fig.height=4, message=FALSE, warning=FALSE, out.width='80%'}
level_vs_pred
```

## $\text{\underline{Conclusion}}$

This project tried to find the model that will predict prices for mid-size apartments in Los Angeles. The obtained values **CV RMSE**, **Holdout RMSE** for all 5 models (OLS, LASSO, CART, Random Forest, GBM) showed that **Random Forest** has the best performance.

Using variable importance plots it was found out that 'f_bathrooms' and 'accommodates' have the biggest influence on the prices for apartments. The high importance of these two variables is not surprising, as their higher values suggest the bigger apartment size.

Additionally, other diagnostics showed that the model performs better for cheaper and smaller apartments. This is may be due to the fact that the dataset doesn't include variables that actually capture the features that make apartments higher in value. 
\newpage

## $\text{\underline{Appendix}}$

*Graph1*: Interaction terms

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=8, fig.width=9}
g_interactions1
```
\newpage
*Graph2*: CART

```{r echo=FALSE}
fancyRpartPlot(cart_model$finalModel, sub = "", palettes = "Blues")
```