---
title: 'Assignment 2: Business Report'
author: "Alima Dzhanybaeva"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Necessary libraries
library(tidyverse)
library(data.table)
library(ggplot2)
library(modelsummary)
library(directlabels)
library(caret)
library(rattle)
library(cowplot)
library(ranger)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Downloading cleaned data
df <- read_csv('cleaned.csv')
```

 
```{r message=FALSE, warning=FALSE, include=FALSE}
# Looking for interactions
price_diff_by_variables2 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){

  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(
      Mean = mean(price, na.rm=TRUE),se = sd(price)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(
    stats, 
    aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(
      stat='identity', 
      position = position_dodge(width=0.9), 
      alpha=0.8)+
    geom_errorbar(
      aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
      position=position_dodge(width = 0.9), 
      width = 0.25)+
    scale_color_manual(
      name=dummy_lab,
      values=c('darkblue','red')) +
    scale_fill_manual(
      name=dummy_lab,
      values=c('darkblue','red')) +
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme_bw()+
    theme(
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      panel.border=element_blank(),
      axis.line=element_line(),
      legend.position = "top",
      legend.box = "vertical",
      legend.text = element_text(size = 5),
      legend.title = element_text(size = 5, face = "bold"),
      legend.key.size = unit(x = 0.4, units = "cm")
    )
}

p1 <- price_diff_by_variables2(df, "f_property_type", "d_air_conditioner", "Property Type", "Air Conditioner")
p2 <- price_diff_by_variables2(df, "f_property_type", "d_pool", "Property Type", "Pool")
p3 <- price_diff_by_variables2(df, "f_property_type", "d_hot_tub", "Property Type", "Hot Tub")
p4 <- price_diff_by_variables2(df, "f_property_type", "d_sound_system", "Property Type", "Sound System")
p5 <- price_diff_by_variables2(df, "f_property_type", "d_coffee_machine", "Property Type", "Coffee Machine")
p6 <- price_diff_by_variables2(df, "f_property_type", "d_dishwasher", "Property Type", "Dishwasher")
p7 <- price_diff_by_variables2(df, "f_property_type", "d_wifi", "Property Type", "Wifi")
p8 <- price_diff_by_variables2(df, "f_property_type", "d_TV", "Property Type", "TV")
p9 <- price_diff_by_variables2(df, "f_property_type", "d_balcony", "Property Type", "Balcony")
p10 <- price_diff_by_variables2(df, "f_property_type", "d_gym", "Property Type", "Gym")
p11 <- price_diff_by_variables2(df, "f_property_type", "d_hair_dryer", "Property Type", "Hair Dryer")
p12 <- price_diff_by_variables2(df, "f_property_type", "d_stove", "Property Type", "Stove")
p13 <- price_diff_by_variables2(df, "f_property_type", "d_breakfast", "Property Type", "Breakfast")
p14 <- price_diff_by_variables2(df, "f_property_type", "d_good_view", "Property Type", "Good View")
g_interactions1 <- plot_grid(p1, p2, p3, p4, p6, p8, p9, p10, p14, nrow=4, ncol=2) 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Defining variables
basic_lev <- c("accommodates", "f_property_type", "beds", "n_days_since")

# Factorized variables
basic_add <- c("f_bathroom", "f_neighbourhood_group_cleansed")

# reviews
reviews <- c("f_number_of_reviews", "review_scores_rating", 
             "reviews_per_month")
# higher orders
poly_lev <- c("accommodates2", "n_days_since2", "n_days_since3")

# Dummy Variables 
dummies <- grep("^d_.*", names(df), value = TRUE)

# Interaction terms
X1 <- c("f_property_type * accommodates", "f_property_type * f_neighbourhood_group_cleansed")

# Additional dummies based on graphs suggestion
X2  <- c("f_property_type*d_air_conditioner", 
         "f_property_type*d_pool",
         "f_property_type*d_hot_tub",
         "f_property_type*d_dishwasher",
         "f_property_type*d_TV",
         "f_property_type*d_balcony", 
         "f_property_type*d_gym",
         "f_property_type*d_good_view")

# all dummies with property type
X3  <- c("accommodates*f_neighbourhood_group_cleansed",
         paste0("(f_property_type) * (",
                paste(dummies, collapse=" + "),")"))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create models in levels models: 1-8
modellev1 <- " ~ accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews, poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies, X3),collapse = " + "))

model_table_view <- data.frame(Model = c('M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8'),
                               Predictors = c('# of Accommodates', 
                               'M1 + Property Type + Number of Beds + Number of Days Since the First Review', 
                               'M2 + # of bathrooms + Neighbourhood group + Reviews per Month + Review Score Rating + # of Reviews',
                               'M3 + # of Accommodates Squared + Squared and Cubic Terms # of Days Since the First Review',
                               'M4 + (Property Type * Number of Accommodates) + (Property Type * Neighbourhood Group)',
                               'M5 + (Property Type * several Amenities Dummies)',
                               'M6 + all Dummy Vars',
                               'M7 + (# of Accommodates * Neighbourhood group) + (Property Type * all Dummy Vars)'))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create a holdout set
smp_size <- floor(0.2 * nrow(df))
set.seed(12345)
holdout_ids <- sample(seq_len(nrow(df)), size = smp_size)
df$holdout <- 0
df$holdout[holdout_ids] <- 1
#Hold-out set
data_holdout <- df %>% filter(holdout == 1)
#Working set
data_work <- df %>% filter(holdout == 0)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Working data set:
k_folds=5 # number of folds
set.seed(12345)
folds_i <- sample(rep(1:k_folds, length.out = nrow(data_work) ))
mse_lev <- function(pred, y) {
  (mean((pred - y)^2, na.rm=T))
}
# Create Results
model_results_cv <- list()
for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  # Initialize values
  rmse_train <- c()
  rmse_test <- c()
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  # Do the k-fold estimation
  for (k in 1:k_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)
    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train[,yvar] %>% pull)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_test[,yvar] %>% pull)**(1/2)
  }
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}

model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)
t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                  "Test RMSE")
OLS_models <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(OLS_models) <- column_names

# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))

model_result_plot <- ggplot(data = t1_levels,
                                   aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
  geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
  scale_color_manual(name="",
                     values=c("#fde725","#440154")) +
  geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  theme_bw()
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Set lasso tuning parameters:
train_control <- trainControl(method = "cv", number = k_folds)
tune_grid <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))

vars_model_1 <- c(basic_lev, basic_add, reviews, dummies)
vars_model_7 <- c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies) # Model 7
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# OLS 
set.seed(12345)
system.time({
  ols_model <- train(
    formula(paste0("price ~", paste0(vars_model_7, collapse = " + "))),
    data = data_work,
    method = "lm",
    trControl = train_control
  )
})
ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# LASSO               
set.seed(12345)
system.time({
  lasso_model <- caret::train(
    formula(paste0("price ~", paste0(vars_model_7, collapse = " + "))),
    data = data_work,
    method = "glmnet",
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    preProcess = c("center", "scale"),
    trControl = train_control
  )
})

lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  rename(coefficient = `s1`)
print(lasso_coeffs)
lasso_coeffs_nz <- lasso_coeffs %>%
  filter(coefficient!=0)

lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])
regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_nz, by = "variable", all=TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# CART        
set.seed(12345)
system.time({
  cart_model <- train(
    formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
    data = data_work,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Random Forest     
tune_grid <- expand.grid(
  .mtry = c(8),
  .splitrule = "variance",
  .min.node.size = c(50)
)

set.seed(12345)
system.time({
rf_model <- train(
  formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
  data = data_work,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# GBM              
gbm_grid <-  expand.grid(interaction.depth = c(5, 10),
                         n.trees = 250, 
                         shrinkage = 0.1,
                         n.minobsinnode = 20
)

set.seed(12345)

system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(vars_model_1, collapse = " + "))),
                     data = data_work,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model$finalModel$mtry,
  rf_model$finalModel$min.node.size
),
nrow=1, ncol=2,
dimnames = list("Model A",
                c("Min vars","Min nodes"))
)

final_models <-
  list("OLS" = ols_model,
       "LASSO" = lasso_model,
       "CART" = cart_model,
       "Random forest"= rf_model,
       "GBM"  = gbm_model
       )
results <- resamples(final_models) %>% summary()

results_r2 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV R-squared" = ".")

results_rmse <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

result_holdout_rmse <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Diagnostics

# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}
rf_model_var_imp <- ranger::importance(rf_model$finalModel)/1000
rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

# Importance plot for top 10
rf_model_var_imp_plot_b <- ggplot(
  rf_model_var_imp_df[1:10,], 
  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  labs(title = 'Simple variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4)) +
  theme_bw()

# Grouped importance plot
varnames <- rf_model$finalModel$xNames

f_neighbourhood_group_cleansed_varnames <- grep("f_neighbourhood_group_cleansed",varnames, value = TRUE)

f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_group_cleansed=f_neighbourhood_group_cleansed_varnames,
               f_property_type = f_property_type_varnames,
               f_bathroom = "f_bathroom",
               n_days_since = "n_days_since",
               accommodates = "accommodates",
               beds = "beds")

rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)

rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                            imp = rf_model_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_var_imp_grouped_plot <- ggplot(
  rf_model_var_imp_grouped_df, 
  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +   
  xlab("Variable Name") +
  labs(title = 'Grouped variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4)) +
  theme_bw()
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# PDP: partial dependence plots 

# 1) Number of accommodates
pdp_n_acc <- pdp::partial(rf_model, 
                          pred.var = "accommodates", 
                          pred.grid = distinct_(data_holdout, "accommodates"), 
                          train = data_work)

pdp_acc_plot<- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color='black', size=2) +
  geom_line(color='black', size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  labs(title = 'Partial dependence plot for # of accommodates') + 
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bw()

# 2) Property type
pdp_propertytype <- pdp::partial(rf_model, pred.var = "f_property_type", pred.grid = distinct_(data_holdout, "f_property_type"), train = data_work)

pdp_ptype_plot <- pdp_propertytype %>%
  autoplot( ) +
  geom_point(color='black', size=2) +
  geom_line(color='black', size=1) +
  ylab("Predicted price") +
  xlab("Property type") +
  labs(title = 'Partial dependence plot for Property Type') + 
  theme_bw() 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Subsample performance: RMSE / mean(y)
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model, newdata = data_holdout))

first <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(accommodates <= 3, "small apt", "bigger apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )
second <- data_holdout_w_prediction %>%
  group_by(f_neighbourhood_group_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )
third <- data_holdout_w_prediction %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )
fourth <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )
# Save output
colnames(first) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(second) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(third) <- c("", "RMSE", "Mean price", "RMSE/price")
fourth <- cbind("All", fourth)
colnames(fourth) <- c("", "RMSE", "Mean price", "RMSE/price")
line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Neighbourhood", "", "", "")
result_2 <- rbind(line2, first, line1, third, line3, second, fourth) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
Ylev <- data_holdout[["price"]]
# Predicted values
prediction_holdout_pred <- as.data.frame(predict(gbm_model, newdata = data_holdout, interval="predict")) 
predictionlev_holdout <- cbind(data_holdout[,c("price","accommodates")],
                               prediction_holdout_pred)
# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout[,3] )
# Check the differences
d$elev <- d$ylev - d$predlev
# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = "darkblue", size = 1,
                 alpha = 0.5, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 350, yend =350), size=0.8, color="black", linetype=2) +
  labs(y = "Price", x = "Predicted price") +
  theme_bw() 
level_vs_pred
```

## $\text{\underline{Introduction}}$

In this project, I tried to find the best price prediction model for mid-size apartments in Los Angeles. The results for 5 models (OLS, LASSO, CART, Random Forest, GBM) showed the lowest RMSE of 73.69 for *Random Forest*,  suggesting the best predictive performance.

## $\text{\underline{Cleaning data}}$

The original dataset for Los Angeles includes 40438 observations and 75 variables, and was scraped from Airbnb on December 7th 2022.

Firstly, the variables that won't be helpful for the prediction of prices and the ones that had a lot of missing values were dropped from the dataset.

As the goal of the project is to predict prices for mid-size apartments the dataset was filtered for the property types ("Entire condo","Entire loft", "Entire serviced apartment", "Entire home/apt", "Entire rental unit") and number of accommodates between 2 and 6. Additionally, the 'price' variable was filtered for the values between 0 and 800 USD.

After additional transformation of existing variables, addition of new variables, and imputation of the values for the missing values we ended up 11890 observations and 59 variables.

## $\text{\underline{Models}}$

First of all we need to decide which variables to include to the models. Therefore, I created 8 models with different combinations of variables and their functional forms to later run the regressions, look at the results for different measurements and decide which one to use.
In the table below you can get familiar with the variables that were added to each model:

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
knitr::kable(model_table_view) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

The results for all eight models are presnted in the table below:

```{r echo=FALSE}
knitr::kable(OLS_models) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center")
```

Root Mean Squared Error (RMSE) and Bayesian Information Criterion (BIC) are a statistical model selection criterion used for comparing different models. The lower the RMSE and BIC values, the better the fit of the model to the data.
Even though **Training RMSE** is the lowest for the *Model 8*, the difference between *Model 7* is negligible. Moreover, **BIC** and **Test RMSE** are the lowest for *Model 7*.

As for other models (**CART**, **Random Forest**, and **GBM**), following variables are used: number of accommodates, property type, number of beds, number of days since the first review, factor variables for the number of bathrooms, neighbourhood group, factor variable for number of reviews, rating, number of reviews per month, different polynomials, and all dummy variables.

The results for all 5 models are presented in the table below:

```{r echo=FALSE, message=FALSE, warning=FALSE}
final_results_all_models <- cbind(results_rmse, result_holdout_rmse, results_r2)
knitr::kable(final_results_all_models) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center")
```

**Random Forest** showed the best performance with the lowest values for **CV RMSE**, **Holdout RMSE** and the highest value for **CV R-squared**.

## $\text{\underline{Diagnostics}}$

As **Random Forest** is a "black box" method it is quite hard to understand the inner workings of the model and the relationship between the input variables and the predictions, as it is represented by a combination of many decision trees and not by mathematical formula like in linear regressions.

Nevertheless, we can try to uncover the obtained patterns with the variable importance plot, partial dependence plot, and plot for actual vs predicted prices.

**Importance of the variables**

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=4}
# ploting the variable importance plot
rf_model_var_imp_plot_b
rf_model_var_imp_grouped_plot
```

It is noticeable that 'f_bathroom' and 'accommodates' are the two most important variables, as they together account for around 30% in the 'Single variable importance plot' and 60% in the 'Grouped variable importance plot'.

Another important variables are: 'n_days_since', 'f_property_type', 'beds', 'f_neighbourhood_group_cleansed', and 'reviews_per_month'.

**Partial dependence plot**

```{r echo=FALSE, fig.align='center', fig.height=4, message=FALSE, warning=FALSE, out.width='50%'}
pdp_acc_plot
```

As we can see from the partial dependence plot for the number of accommodates, as the number of guests that can check in into apartment rises the predicted price also increases.

**Actual VS Predicted prices**

The figure below implies that the model is performing better for cheaper apartments.

```{r echo=FALSE, fig.align='center', fig.height=4, message=FALSE, warning=FALSE, out.width='50%'}
level_vs_pred
```

## $\text{\underline{Conclusion}}$

This project tried to find the model that will predict prices for mid-size apartments in Los Angeles. The obtained values **CV RMSE**, **Holdout RMSE** for all 5 models (OLS, LASSO, CART, Random Forest, GBM) showed that **Random Forest** has the best performance.

Using variable importance plots it was found out that 'f_bathrooms' and 'accommodates' have the biggest influence on the prices for apartments. The high importance of these two variables is not surprising, as their higher values suggest the bigger apartment size.

Additionally, other diagnostics showed that the model performs better for cheaper and smaller apartments. This is may be due to the fact that the dataset doesn't include variables that actually capture the features that make apartments higher in value. 